{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rtweet)        # Used for extracting the tweets\n",
    "library(tm)            # Text mining cleaning\n",
    "library(stringr)       # Removing characters\n",
    "library(qdapRegex)     # Removing URLs \n",
    "library(wordcloud2)    # Creating the wordcloud\n",
    "library(httpuv)\n",
    "library(plyr)\n",
    "library(NLP)\n",
    "library(syuzhet)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## store api keys (these are empty example values; replace with your own keys)\n",
    "api_key <- \"xxxxxxxxxxxx\"\n",
    "api_secret_key <- \"xxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "## authenticate via web browser\n",
    "token <- create_token(\n",
    "  app = \"random1258475983\",\n",
    "  consumer_key = api_key,\n",
    "  consumer_secret = api_secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## most recent to least tweet order. Can set to 18000 I believe is the limit.\n",
    "tweets <- get_timelines(c(\"twitter_account\"), n = 18000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter <- search_tweets(q = \"words or phrase to search for in twitter\", n = 18000, lang = \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simple text cleaning\n",
    "text <- str_c(tweets$text, collapse = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simple text cleaning\n",
    "text2 <- str_c(twitter$text, collapse = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## more text cleaning \n",
    "text <- \n",
    "  text %>%\n",
    "  str_remove(\"\\\\n\") %>%                   # remove linebreaks\n",
    "  rm_twitter_url() %>%                    # Remove URLS\n",
    "  rm_url() %>%\n",
    "  str_remove_all(\"#\\\\S+\") %>%             # Remove any hashtags\n",
    "  str_remove_all(\"@\\\\S+\") %>%             # Remove any @ mentions\n",
    "  removeWords(stopwords(\"english\")) %>%   # Remove common words (a, the, it etc.)\n",
    "  removeNumbers() %>%\n",
    "  stripWhitespace() %>%\n",
    "  removeWords(c(\"amp\"))                   # Final cleanup of other small things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## more text cleaning \n",
    "text2 <- \n",
    "  text %>%\n",
    "  str_remove(\"\\\\n\") %>%                   # remove linebreaks\n",
    "  rm_twitter_url() %>%                    # Remove URLS\n",
    "  rm_url() %>%\n",
    "  str_remove_all(\"#\\\\S+\") %>%             # Remove any hashtags\n",
    "  str_remove_all(\"@\\\\S+\") %>%             # Remove any @ mentions\n",
    "  removeWords(stopwords(\"english\")) %>%   # Remove common words (a, the, it etc.)\n",
    "  removeNumbers() %>%\n",
    "  stripWhitespace() %>%\n",
    "  removeWords(c(\"amp\"))                   # Final cleanup of other small things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into a summary table\n",
    "textCorpus <- \n",
    "  Corpus(VectorSource(text)) %>%\n",
    "  TermDocumentMatrix() %>%\n",
    "  as.matrix()\n",
    "\n",
    "textCorpus <- sort(rowSums(textCorpus), decreasing=TRUE)\n",
    "textCorpus <- data.frame(word = names(textCorpus), freq=textCorpus, row.names = NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into a summary table\n",
    "textCorpus <- \n",
    "  Corpus(VectorSource(text2)) %>%\n",
    "  TermDocumentMatrix() %>%\n",
    "  as.matrix()\n",
    "\n",
    "textCorpus <- sort(rowSums(textCorpus), decreasing=TRUE)\n",
    "textCorpus <- data.frame(word = names(textCorpus), freq=textCorpus, row.names = NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build wordcloud \n",
    "wordcloud <- wordcloud(data = textCorpus, minRotation = 0, maxRotation = 0, ellipticity = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build wordcloud \n",
    "wordcloud2 <- wordcloud2(data = textCorpus, minRotation = 0, maxRotation = 0, ellipticity = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## can group a bunch of twitter accounts together \n",
    "\n",
    "TweetsToWordcloud <- function(username){\n",
    "  \n",
    "  tweets <- get_timelines(username, n = 18000)\n",
    "  \n",
    "  # Clean the data\n",
    "  text <- str_c(tweets$text, collapse = \"\") %>%\n",
    "  str_remove(\"\\\\n\") %>%                   # remove linebreaks\n",
    "  rm_twitter_url() %>%                    # Remove URLS\n",
    "  rm_url() %>%\n",
    "  str_remove_all(\"#\\\\S+\") %>%             # Remove any hashtags\n",
    "  str_remove_all(\"@\\\\S+\") %>%             # Remove any @ mentions\n",
    "  removeWords(stopwords(\"english\")) %>%   # Remove common words (a, the, it etc.)\n",
    "  removeNumbers() %>%\n",
    "  stripWhitespace() %>%\n",
    "  removeWords(c(\"amp\"))                   # Final cleanup of other small changes\n",
    "  \n",
    "    # Convert the data into a summary table\n",
    "  textCorpus <- \n",
    "    Corpus(VectorSource(text)) %>%\n",
    "    TermDocumentMatrix() %>%\n",
    "    as.matrix()\n",
    "  \n",
    "  textCorpus <- sort(rowSums(textCorpus), decreasing=TRUE)\n",
    "  textCorpus <- data.frame(word = names(textCorpus), freq=textCorpus, row.names = NULL)\n",
    "  \n",
    "  wordcloud <- wordcloud2(data = textCorpus, minRotation = 0, maxRotation = 0, ellipticity = 0.6)\n",
    "  return(wordcloud)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TweetsToWordcloud(username = \"twitter_account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Continuing process to get sentiment analysis of twitter phrases or accounts\n",
    "sentiment<-get_nrc_sentiment((text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentimentscores<-data.frame(colSums(sentiment[,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(Sentimentscores)<-\"Score\"\n",
    "Sentimentscores<-cbind(\"sentiment\"=rownames(Sentimentscores),Sentimentscores)\n",
    "rownames(Sentimentscores)<-NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data=Sentimentscores,aes(x=sentiment,y=Score))+geom_bar(aes(fill=sentiment),stat = \"identity\")+\n",
    "  theme(legend.position=\"none\")+\n",
    "  xlab(\"Sentiments\")+ylab(\"Scores\")+ggtitle(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
