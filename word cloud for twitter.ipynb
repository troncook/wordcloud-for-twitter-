{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rtweet)        # Used for extracting the tweets\n",
    "library(tm)            # Text mining cleaning\n",
    "library(stringr)       # Removing characters\n",
    "library(qdapRegex)     # Removing URLs \n",
    "library(wordcloud2)    # Creating the wordcloud\n",
    "library(httpuv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## store api keys (these are empty example values; replace with your own keys)\n",
    "api_key <- \"\"\n",
    "api_secret_key <- \"\"\n",
    "\n",
    "## authenticate via web browser\n",
    "token <- create_token(\n",
    "  app = \"\",\n",
    "  consumer_key = api_key,\n",
    "  consumer_secret = api_secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## most recent to least tweet order. Can set to 18000 I believe is the limit.\n",
    "tweets_pab <- get_timelines(c(\"\"), n = 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simple text cleaning\n",
    "text <- str_c(tweets_pab$text, collapse = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## more text cleaning \n",
    "text <- \n",
    "  text %>%\n",
    "  str_remove(\"\\\\n\") %>%                   # remove linebreaks\n",
    "  rm_twitter_url() %>%                    # Remove URLS\n",
    "  rm_url() %>%\n",
    "  str_remove_all(\"#\\\\S+\") %>%             # Remove any hashtags\n",
    "  str_remove_all(\"@\\\\S+\") %>%             # Remove any @ mentions\n",
    "  removeWords(stopwords(\"english\")) %>%   # Remove common words (a, the, it etc.)\n",
    "  removeNumbers() %>%\n",
    "  stripWhitespace() %>%\n",
    "  removeWords(c(\"amp\"))                   # Final cleanup of other small changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into a summary table\n",
    "textCorpus <- \n",
    "  Corpus(VectorSource(text)) %>%\n",
    "  TermDocumentMatrix() %>%\n",
    "  as.matrix()\n",
    "\n",
    "textCorpus <- sort(rowSums(textCorpus), decreasing=TRUE)\n",
    "textCorpus <- data.frame(word = names(textCorpus), freq=textCorpus, row.names = NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# build wordcloud \n",
    "wordcloud <- wordcloud2(data = textCorpus, minRotation = 0, maxRotation = 0, ellipticity = 0.6)\n",
    "wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## can group a bunch of twitter accounts together \n",
    "\n",
    "TweetsToWordcloud <- function(){\n",
    "  \n",
    "  tweets <- get_timelines(username, n = 3200)\n",
    "  \n",
    "  # Clean the data\n",
    "  text <- str_c(tweets$text, collapse = \"\") %>%\n",
    "  str_remove(\"\\\\n\") %>%                   # remove linebreaks\n",
    "  rm_twitter_url() %>%                    # Remove URLS\n",
    "  rm_url() %>%\n",
    "  str_remove_all(\"#\\\\S+\") %>%             # Remove any hashtags\n",
    "  str_remove_all(\"@\\\\S+\") %>%             # Remove any @ mentions\n",
    "  removeWords(stopwords(\"english\")) %>%   # Remove common words (a, the, it etc.)\n",
    "  removeNumbers() %>%\n",
    "  stripWhitespace() %>%\n",
    "  removeWords(c(\"amp\"))                   # Final cleanup of other small changes\n",
    "  \n",
    "    # Convert the data into a summary table\n",
    "  textCorpus <- \n",
    "    Corpus(VectorSource(text)) %>%\n",
    "    TermDocumentMatrix() %>%\n",
    "    as.matrix()\n",
    "  \n",
    "  textCorpus <- sort(rowSums(textCorpus), decreasing=TRUE)\n",
    "  textCorpus <- data.frame(word = names(textCorpus), freq=textCorpus, row.names = NULL)\n",
    "  \n",
    "  wordcloud <- wordcloud2(data = textCorpus, minRotation = 0, maxRotation = 0, ellipticity = 0.6)\n",
    "  return(wordcloud)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
